{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CSI 4106 Introduction to Artificial Intelligence** <br/>\n",
        "*Assignment 1: Data Preparation*\n",
        "\n",
        "# Identification\n",
        "\n",
        "Name: <br/>\n",
        "Student Number:\n",
        "\n",
        "# Exploratory Analysis\n",
        "\n",
        "## Import important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Dataset\n",
        "\n",
        "As outlined in the project description, it should be possible for the correctors to ecute your notebook without requiring any downloads.\n",
        "\n",
        "To facilitate access to the dataset without the need for downloads, use the data ovided in the public GitHub repository and provide a link to the raw version of the taset.\n",
        "\n",
        "The link to the raw version is as follows:\n",
        "\n",
        "*https://raw.githubusercontent.com/GITHUB_USERNAME/REPOSITORY_NAME/main/DATASETNAME.v*\n",
        "\n",
        "For example:\n",
        "\n",
        "[https://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv]ttps://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv)\n",
        "\n",
        "Now provide the link to YOUR dataset and read the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "url = # provide the link to the raw version of dataset. You *need* to provide a link to *your own* github repository. DO NOT use the link that is provided as an example.\n",
        "\n",
        "dataset = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guidelines\n",
        "\n",
        "The following are the questions for Assignment 1. Under each question, we have provided an initial code cell. You are encouraged to add additional code cells to maintain logical separation of your code. For instance, place the definition of a function in one cell and its execution in a subsequent cell. This approach will help preserve clarity and enhance readability by avoiding the inclusion of excessive code within a single cell.\n",
        "\n",
        "1. **Analysis of Missing Values**: Examine the datasets to identify and assess ssing values in various attributes. Missing values may be represented by symbols ch as '?', empty strings, or other placeholders.\n",
        "\n",
        "    1.1 In the list of options, what are the datasets that contain missing values? ecifically, which attribute or attributes has missing values?\n",
        "\n",
        "    1.2 Describe the methodology used for this investigation, and provide the rresponding code.\n",
        "\n",
        "    1.1 Data imputation involves replacing missing or incomplete data with substituted values to preserve the dataset's integrity for subsequent analysis. Propose imputation strategies for each attribute with missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **Select and familiarize yourself with a classification task:** Choose one of e provided datasets for further investigation. It is advisable to select a dataset ntaining a sufficiently large number of examples, ideally around 1,000, to ensure bust results when applying machine learning algorithms in the subsequent assignment.\n",
        "\n",
        "    2.1 What is the objective of the task? Is it intended for a specific plication? Do you possess expertise in this particular domain of application?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Attribute Analysis**: \n",
        "\n",
        "    3.1 Determine which attributes lack informativeness and should be excluded to prove the effectiveness of the machine learning analysis. If all features are emed relevant, explicitly state this conclusion.\n",
        "\n",
        "    3.2 Examine the distribution of each attribute (column) within the dataset. Utilize histograms or boxplots to visualize the distributions, identifying any underlying patterns or outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. **Class Distribution Analysis**: Investigate the distribution of class labels within the dataset. Employ bar plots to visualize the frequency of instances for each class, and assess whether the dataset is balanced or imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. **Preprocessing**: \n",
        "\n",
        "    5.1 For numerical features, determine the best transformation to use. Indicate e transformation that seems appropriate and why. Include the code illustrating how  apply the transformation. For at least one attribute, show the distribution before d after the transformation. See [Preprocessing data](https://scikit-learn.org/able/modules/preprocessing.html).\n",
        "\n",
        "    5.2 For categorical features, show how to apply [one-hot encoding](https://ikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).  your dataset does not have categorical data, show how to apply the one-hot encoder  the label (target variable)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. **Training and target data**: Set the Python variable `X` to designate the data and `y` to designate the target class. Make sure to select only the informative features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. **Training and test sets**: Split the dataset into training and testing sets. Reserve 20% of data for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------------------------------------------------------------\n",
        "\n",
        "# References\n",
        "\n",
        "Make sure you provide references to ALL sources used (articles, code, algorithms).\n",
        "\n",
        "## AI transcript\n",
        "**Hint:** To share a link to your colab notebook, click on \"share\" on the top right. Then, under *General access* , change *Restricted* to \"Anyone with the link\"."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}